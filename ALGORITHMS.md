# System Algorithms Documentation

This document provides a comprehensive overview of the intelligent algorithms powering the application. It details what each algorithm does, where it is implemented in the codebase, and where you can experience it in the user interface.

---

## 1. Latent Semantic Analysis (LSA) Engine
**Class:** `LSAEngine` in `scraper/algorithms/lsa.py`

### What it does
LSA is a Natural Language Processing (NLP) technique. It analyzes relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms.
-   **In our app:** It builds a semantic vector space using all the Skills and Company Tech Stacks in our database. It then projects new text (like your resume or a job description) into this space to calculate how semantically similar they are, even if they don't use the exact same keywords.

### Where it is used
-   **Feature:** **Resume Matcher** & **Job Compatibility**
-   **Code Location:** `scraper/views.py`: `calculate_similarity_score` called by `matcher_view`.

### How to use it
1.  Navigate to **Result Analysis** (Matcher).
2.  Enter a Job Description.
3.  The system compares your profile's resume against the description.
4.  The **Compatibility Score** (0-100%) is generated by this LSA Engine.

---

## 2. Recommender System (Content-Based Filtering)
**Class:** `RecommenderSystem` in `scraper/algorithms/recommender.py`

### What it does
This algorithm recommends items (Companies) to a user based on the features of items they already like or match their profile.
-   **In our app:** It uses **Jaccard Similarity** to compare the "Tech Stack" tags of a company (e.g., "Python, React, AWS") against your resume or another company you are interested in.

### Where it is used
-   **Feature:** **Interview Prep**
-   **Code Location:** `scraper/views.py`: `interview_prep_view`.

### How to use it
1.  Navigate to **Interview Prep**.
2.  Select a target company (e.g., "Google").
3.  The system will display **"Recommended Similar Companies"** (e.g., "Spotify", "Amazon") based on tech stack overlap.

---

## 3. PageRank (Centrality Analysis)
**Class:** `PageRank` in `scraper/algorithms/pagerank.py`

### What it does
Initially designed by Google to rank web pages, PageRank measures the importance of nodes in a graph based on the quality and quantity of links pointing to them.
-   **In our app:** It runs on our **Skill Graph**. A skill is considered "important" if many other skills depend on it (are prerequisites for it) or if other important skills link to it.

### Where it is used
-   **Feature:** **Career Roadmap Visualization**
-   **Code Location:**
    -   `scraper/algorithms/pagerank.py`: `update_db_scores` (runs in background/scripts).
    -   `scraper/views.py`: `path_node_detail_view` (displays the score).

### How to use it
1.  Navigate to a **Career Path** (Pathfinder Result).
2.  Click on a specific step (Node).
3.  The **"Importance Score"** shown for that skill is calculated via PageRank. Higher score = more central/critical skill.

---

## 4. Bayesian Predictor (Naive Bayes)
**Class:** `BayesianPredictor` in `scraper/algorithms/bayesian.py`

### What it does
A probabilistic classifier typically used to predict the likelihood of an event based on prior knowledge of conditions.
-   **In our app:** It predicts the **Success Probability** (likelihood of getting hired or mastering a path) based on the set of skills you are learning. It uses "Market Signals" (success/failure rates of specific skills in the job market) to calculate this probability.

### Where it is used
-   **Feature:** **Pathfinder Results**
-   **Code Location:** `scraper/views.py`: `pathfinder_view`.

### How to use it
1.  Complete the **Pathfinder Quiz**.
2.  On the results page, look for the **"Predicted Success Probability"** card.
3.  The percentage and the "Skill Impact" details are derived from this Bayesian analysis of the skills in your generated roadmap.

---

## 5. Simulated Annealing (Scheduler Optimization)
**Class:** `SimulatedAnnealingScheduler` in `scraper/algorithms/scheduler.py`

### What it does
A probabilistic technique for approximating the global optimum of a given function. It is often used for scheduling or logistics problems.
-   **In our app:** It generates an **Optimal Weekly Study Schedule**. It tries to minimize "Energy" (cost), where "High Cost" = burnout (studying same thing too many days in a row) or uneven distribution. usage.

### Where it is used
-   **Feature:** **Pathfinder Results**
-   **Code Location:** `scraper/views.py`: `pathfinder_view`.

### How to use it
1.  Complete the **Pathfinder Quiz**.
2.  Scroll to the **"Optimized Weekly Schedule"** section.
3.  The distribution of subjects across Mon-Sun is generated by this algorithm to prevent burnout.

---

## 6. Apriori Algorithm (Association Rule Mining)
**Class:** `AprioriGenerator` in `scraper/algorithms/apriori.py`

### What it does
A classic data mining algorithm used for mining frequent itemsets and relevant association rules. "People who bought X also bought Y".
-   **In our app:** It acts as a **"Missing Skill Suggester"**. It looks at the skills you matched with and suggests *other* skills that are frequently associated with them in our graph structure, especially those with high market value.

### Where it is used
-   **Feature:** **Result Analysis** (Matcher)
-   **Code Location:** `scraper/views.py`: `matcher_view`.

### How to use it
1.  Go to **Result Analysis**.
2.  Enter a Job Description and submit.
3.  Look for the **"Strategic Additions"** or **"Recommended Skills"** section. These suggestions come from the Apriori rules.

---

## 7. Multi-Criteria Dijkstra (Graph Search)
**Class:** `SkillGraph` in `scraper/algorithms/graph.py`

### What it does
An extension of Dijkstra's shortest path algorithm that considers multiple "weights" (costs) simultaneously, such as Time vs. Difficulty.
-   **In our app:** Use to find the shortest path between two career points (e.g., "HTML" to "Full Stack Dev").

### Where it is used
-   **Feature:** **Roadmap Explorer** (Legacy/Debug View)
-   **Code Location:** `scraper/views.py`: `roadmap_view` (located at `/roadmap`).

### How to use it
1.  Navigate to `/roadmap` (manually).
2.  Select a Start Node and End Node.
3.  The algorithm calculates the best path based on your chosen criterion (Fastest vs. Easiest).

---

## 8. Personality Classifier (Vector-Based)
**Class:** `PersonalityClassifier` in `scraper/algorithms/classifier.py`

### What it does
Uses a simple K-Nearest Neighbors (KNN) style centroid approach to map diverse user answers into one of the 16 MBTI-style personality types.
-   **In our app:** Maps your 4-dimensional vector (EI, SN, TF, JP scores) to the closest standard personality type centroid.

### Where it is used
-   **Feature:** **Personality Assessment**
-   **Code Location:** `scraper/views.py`: `personality_view`.

### How to use it
1.  Take the **Personality Quiz**.
2.  The final result "You are an INTJ" is determined by minimizing the Euclidean distance between your answer vector and the defined personality centroids.
